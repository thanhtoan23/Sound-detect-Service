# Luá»“ng Thá»±c Thi ChÆ°Æ¡ng TrÃ¬nh - Smart Audio Detection Service
## Äiá»ƒm ÄÃ­ch: smart_audio_pipeline.py

---

## ğŸ“Š SÆ  Äá»’ Tá»”NG QUAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENTRY POINTS (3 Äiá»ƒm VÃ o)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. gui_app.py           (GUI vá»›i Tkinter)                  â”‚
â”‚  2. api.py               (REST API vá»›i Flask)               â”‚
â”‚  3. smart_audio_pipeline.py (Demo Console - TRá»°C TIáº¾P)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  SmartAudioSystem (Pipeline)       â”‚
        â”‚  (smart_audio_pipeline.py)         â”‚
        â”‚                                    â”‚
        â”‚  - Khá»Ÿi táº¡o Processor + Classifier â”‚
        â”‚  - VÃ²ng láº·p xá»­ lÃ½ Ã¢m thanh         â”‚
        â”‚  - Hiá»ƒn thá»‹ káº¿t quáº£                â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                     â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚AudioProcessorâ”‚     â”‚ AudioClassifier â”‚
      â”‚(Lá»c nhiá»…u, AGC)â”‚      â”‚(PhÃ¢n loáº¡i AI)     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                     â”‚
             â”œâ”€â”€â–º Raw Audio        â”‚
             â”‚   Input             â”‚
             â”‚   (from Mic)        â”‚
             â”‚                     â”‚
             â””â”€â”€â”€â”€â”€â–º Clean Audio â”€â”€â–º AI Model
                    (DSP Out)       (DL Prediction)
```

---

## ğŸ¯ CHI TIáº¾T LUá»’NG THá»°C THI

### **1. Äá»ŒC FILE VÃ€ KHá»I Äá»˜NG**

```python
if __name__ == "__main__":
    system = SmartAudioSystem()
    system.run_demo()
```

**File:** [smart_audio_pipeline.py](smart_audio_pipeline.py#L180-L182)

### **2. KHá»I Äá»˜NG Há»† THá»NG (SmartAudioSystem.__init__)**

```python
class SmartAudioSystem:
    def __init__(self):
        # BÆ°á»›c 1: Khá»Ÿi táº¡o Processor (DSP)
        self.processor = AudioProcessor(rate=16000)
        
        # BÆ°á»›c 2: Khá»Ÿi táº¡o Classifier (AI + Model Load)
        self.classifier = AudioClassifier(rate=16000)
        
        self.is_running = False
        self.console = Console()
```

**Chuá»—i khá»Ÿi táº¡o:**
1. `AudioProcessor` â†’ Chuáº©n bá»‹ lá»c nhiá»…u, AGC (Automatic Gain Control)
2. `AudioClassifier` â†’ Load model Deep Learning (audio_cnn_best.h5)

**File:** [smart_audio_pipeline.py](smart_audio_pipeline.py#L15-L25)

### **3. KHá»I Äá»˜NG STREAM AUDIO (SmartAudioSystem.start)**

```python
def start(self):
    self.classifier.start_stream()  # Má»Ÿ Mic, PyAudio stream
    self.is_running = True
    self.processor.reset_states()   # Reset bá»™ lá»c & AGC
    self.console.print("[bold green]Smart Audio Pipeline Started...[/bold green]")
```

**File:** [smart_audio_pipeline.py](smart_audio_pipeline.py#L27-L32)

### **4. VÃ’NG Láº¶P CHÃNH (SmartAudioSystem.run_demo)**

```python
def run_demo(self):
    self.start()
    
    # Hiá»ƒn thá»‹ báº£ng trá»±c quan
    table = Table(title="Smart Audio Analysis")
    
    try:
        with Live(table, refresh_per_second=4) as live:
            while self.is_running:
                result = self.process_and_predict()  # â­ HÃ€M TRUNG TÃ‚M
                
                if result:
                    # Cáº­p nháº­t báº£ng vá»›i káº¿t quáº£
                    live.update(table)
                
                time.sleep(0.1)
                
    except KeyboardInterrupt:
        self.stop()
```

**File:** [smart_audio_pipeline.py](smart_audio_pipeline.py#L103-L147)

### **5. Xá»¬ LÃ & Dá»° ÄOÃN (SmartAudioSystem.process_and_predict) â­ TRUNG TÃ‚M**

```python
def process_and_predict(self):
    """HÃ m trung tÃ¢m káº¿t há»£p DSP + AI"""
    
    # BÆ¯á»šC 1: Äá»ŒC Dá»® LIá»†U THá»°C (RAW)
    raw_chunk = self.classifier.read_audio_chunk()
    if raw_chunk is None:
        return None
    
    # BÆ¯á»šC 2: Xá»¬ LÃ TÃN HIá»†U (DSP - Lá»c Nhiá»…u + AGC)
    clean_chunk = self.processor.process(raw_chunk)
    
    # BÆ¯á»šC 3: PHÃ‚N LOáº I CÆ  Báº¢N (Rule-based)
    basic_type = self.classifier.classify_sound(clean_chunk)
    
    # BÆ¯á»šC 4: TRÃCH XUáº¤T Äáº¶C TRÆ¯NG
    features = self.classifier.extract_features(clean_chunk)
    
    # BÆ¯á»šC 5: Gá»ŒI MODEL DL (Náº¿u khÃ´ng im láº·ng)
    env_label = None
    env_conf = 0.0
    
    if basic_type != SoundType.SILENCE and features['rms'] > 0.02:
        raw_label, raw_conf = self.classifier._update_env_buffer_and_predict(clean_chunk)
        if raw_label:
            env_label = raw_label
            env_conf = raw_conf
    
    return {
        "basic_type": basic_type,
        "env_label": env_label,
        "env_conf": env_conf,
        "rms_raw": np.sqrt(np.mean(raw_chunk**2)),
        "rms_clean": features['rms'],
        "gain_applied": self.processor.current_gain
    }
```

**File:** [smart_audio_pipeline.py](smart_audio_pipeline.py#L46-L80)

---

## ğŸ“‹ LUá»’NG CHI TIáº¾T - Tá»ªNG BÆ¯á»šC

### **CHI TIáº¾T CÃC BÆ¯á»šC:**

#### **BÆ¯á»šC 1: Äá»ŒC AUDIO (Raw)**
```python
raw_chunk = self.classifier.read_audio_chunk()
```
- **Tá»«:** Microphone (PyAudio Stream)
- **KÃ­ch thÆ°á»›c:** 1024 máº«u (16-bit PCM)
- **Táº§n suáº¥t:** 16000 Hz
- **Äá»‹nh dáº¡ng:** np.int16

**File:** [audio_classifier.py](audio_classifier.py)

---

#### **BÆ¯á»šC 2: Lá»ŒC NHIá»„U & AGC (AudioProcessor)**

```python
clean_chunk = self.processor.process(raw_chunk)
```

**CÃ¡c xá»­ lÃ½ bÃªn trong AudioProcessor:**
1. **Noise Gate** â†’ Lá»c bá» Ã¢m thanh yáº¿u
2. **High-pass Filter** â†’ Loáº¡i bá» táº§n sá»‘ tháº¥p
3. **Noise Subtraction** â†’ Trá»« Ä‘i noise ná»n
4. **AGC (Automatic Gain Control)** â†’ TÄƒng/giáº£m Ä‘á»™ to

**File:** [audio_processor.py](audio_processor.py)

---

#### **BÆ¯á»šC 3: PHÃ‚N LOáº I CÆ  Báº¢N (Rule-based)**

```python
basic_type = self.classifier.classify_sound(clean_chunk)
```

**Logic phÃ¢n loáº¡i:**
```
Input: clean_chunk (Waveform)
  â†“
TÃ­nh RMS, Spectral Centroid, ZCR
  â†“
So sÃ¡nh vá»›i Thresholds:
  - RMS < 0.001           â†’ SILENCE
  - Spectral Centroid cao â†’ SPEECH
  - ZCR tháº¥p              â†’ MUSIC  
  - KhÃ¡c                  â†’ NOISE
  â†“
Output: SoundType (Enum)
```

**Return:** `SoundType.SILENCE | SPEECH | MUSIC | NOISE`

**File:** [audio_classifier.py](audio_classifier.py)

---

#### **BÆ¯á»šC 4: TRÃCH XUáº¤T Äáº¶C TRÆ¯NG**

```python
features = self.classifier.extract_features(clean_chunk)
```

**CÃ¡c Ä‘áº·c trÆ°ng trÃ­ch xuáº¥t:**
- `rms`: Root Mean Square (Ä‘á»™ lá»›n)
- `zcr`: Zero Crossing Rate (sá»‘ láº§n Ä‘á»•i dáº¥u)
- `spectral_centroid`: TÃ¢m táº§n sá»‘
- `mfcc`: Mel-Frequency Cepstral Coefficients
- `chroma`: Äáº·c trÆ°ng mÃ u Ã¢m

**File:** [audio_classifier.py](audio_classifier.py)

---

#### **BÆ¯á»šC 5: Dá»° ÄOÃN DEEP LEARNING**

```python
if basic_type != SoundType.SILENCE and features['rms'] > 0.02:
    raw_label, raw_conf = self.classifier._update_env_buffer_and_predict(clean_chunk)
```

**Luá»“ng chi tiáº¿t:**

```
Input: clean_chunk (1024 máº«u)
  â†“
Buffer Accumulation (TÃ­ch lÅ©y vÃ o buffer)
  â†“
buffer_length >= 5s? (80000 máº«u)
  â”œâ”€ YES: Gá»i Model Dá»± Ä‘oÃ¡n
  â”‚         â†“
  â”‚       Convert waveform â†’ Log-Mel Spectrogram (128, 64, 1)
  â”‚         â†“
  â”‚       ÄÆ°a vÃ o CNN Model (audio_cnn_best.h5)
  â”‚         â†“
  â”‚       Output: Probabilities cho 14 class
  â”‚         â†“
  â”‚       Lá»c Smoothing + Voting (3 frame)
  â”‚         â†“
  â”‚       Output: (label, confidence)
  â”‚
  â””â”€ NO: Chá» dá»¯ liá»‡u thÃªm
```

**Model Output:**
- **Labels:** 14 class (car_horn, cat, dog, speech, ..., unknown)
- **Confidence:** 0.0 - 1.0
- **Smoothing:** Top-3 predictions Ä‘Æ°á»£c smooth Ä‘á»ƒ chá»‘ng nhiá»…u

**File:** [audio_classifier.py](audio_classifier.py)

---

## ğŸ”„ LUá»’NG Dá»® LIá»†U Táº I smart_audio_pipeline.py

```
                  SmartAudioSystem
                  (smart_audio_pipeline.py)
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                         â”‚
         raw_chunk              AudioProcessor
         (16000Hz)                    â”‚
              â”‚                       â”‚
              â”œâ”€â”€(1) read_audioâ”€â”€â”€â”€â”€â”€â–ºâ”‚
              â”‚                       â”‚
              â”‚â—„â”€(2) clean_chunkâ”€â”€â”€â”€â”€â”¤
              â”‚                       â”‚
              â”‚                       â”‚ (DSP Filter)
              â”‚                       â”‚
              â”œâ”€â”€(3) classify_soundâ”€â”€â”¤
              â”‚                   â”‚   â”‚
              â”œâ”€â”€(4) extract_featuresâ”€â”€â”¤
              â”‚     (RMS, ZCR...)     â”‚
              â”‚                       â”‚
         AudioClassifier             â”‚
              â”‚                       â”‚
              â”œâ”€â”€(5) predict DLâ”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚     (CNN Model)       â”‚
              â”‚                       â”‚
              â–¼                       â–¼
         Output Result:
         {
           "basic_type": SoundType,
           "env_label": str (class name),
           "env_conf": float (0.0-1.0),
           "rms_raw": float,
           "rms_clean": float,
           "gain_applied": float
         }
```

---

## ğŸ“Š LUá»’NG TOÃ€N Bá»˜ (End-to-End)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ENTRY POINT                                              â”‚
â”‚    if __name__ == "__main__":                               â”‚
â”‚        system = SmartAudioSystem()                           â”‚
â”‚        system.run_demo()                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. INITIALIZATION (__init__)                                â”‚
â”‚    - Create AudioProcessor()                                â”‚
â”‚    - Create AudioClassifier() + Load Model                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. START SYSTEM (start())                                   â”‚
â”‚    - Start Audio Stream (PyAudio)                           â”‚
â”‚    - Set is_running = True                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MAIN LOOP (run_demo())                                   â”‚
â”‚    while is_running:                                        â”‚
â”‚        result = process_and_predict()  â­ TRUNG TÃ‚M         â”‚
â”‚        display(result)                                      â”‚
â”‚        sleep(0.1)                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ process_and_predict()
        â”‚ (Äá»¤C Lá»ŒC Xá»¬ LÃ)
        â”‚
        â”œâ”€â–º 1ï¸âƒ£  read_audio_chunk()       [Mic Input]
        â”‚       â”‚
        â”‚       â””â”€â–º np.int16 array
        â”‚
        â”œâ”€â–º 2ï¸âƒ£  processor.process()      [DSP Processing]
        â”‚       â”œâ”€ Noise Gate
        â”‚       â”œâ”€ High-pass Filter
        â”‚       â”œâ”€ Noise Subtraction
        â”‚       â””â”€ AGC (Automatic Gain Control)
        â”‚       â”‚
        â”‚       â””â”€â–º Float array (normalized)
        â”‚
        â”œâ”€â–º 3ï¸âƒ£  classify_sound()         [Rule-based]
        â”‚       â”œâ”€ Calculate RMS, ZCR, Spectral features
        â”‚       â”œâ”€ Compare with thresholds
        â”‚       â””â”€â–º SoundType (SILENCE/SPEECH/MUSIC/NOISE)
        â”‚
        â”œâ”€â–º 4ï¸âƒ£  extract_features()       [Feature Extraction]
        â”‚       â””â”€â–º Dict {rms, zcr, ...}
        â”‚
        â””â”€â–º 5ï¸âƒ£  _update_env_buffer_and_predict()  [Deep Learning]
                â”œâ”€ Accumulate 5 seconds of audio
                â”œâ”€ Convert to Log-Mel Spectrogram
                â”œâ”€ Pass through CNN Model (audio_cnn_best.h5)
                â”œâ”€ Smooth predictions (3-frame window)
                â””â”€â–º (env_label: str, env_conf: float)
                    â”œâ”€ car_horn, cat, clock_alarm, ...
                    â””â”€ Confidence: 0.0 ~ 1.0

                â†“ RETURN TO CALLER
                
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ result = {                         â”‚
        â”‚   "basic_type": SoundType,         â”‚
        â”‚   "env_label": str,                â”‚
        â”‚   "env_conf": float,               â”‚
        â”‚   "rms_raw": float,                â”‚
        â”‚   "rms_clean": float,              â”‚
        â”‚   "gain_applied": float            â”‚
        â”‚ }                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 5. DISPLAY RESULTS                â”‚
        â”‚    (Rich Table Format)             â”‚
        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚    â”‚ DSP | Basic | AI Predict â”‚   â”‚
        â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
        â”‚    â”‚ info| info | info        â”‚   â”‚
        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ sleep(0.1) - chá» chunk tiáº¿p theo  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CÃC FILE LIÃŠN QUAN

| File | Vai trÃ² | Chá»©c nÄƒng |
|------|---------|----------|
| [smart_audio_pipeline.py](smart_audio_pipeline.py) | **TRUNG TÃ‚M** | Káº¿t há»£p DSP + AI, vÃ²ng láº·p chÃ­nh |
| [audio_processor.py](audio_processor.py) | DSP Layer | Lá»c nhiá»…u, AGC, tÄƒng/giáº£m Ä‘á»™ to |
| [audio_classifier.py](audio_classifier.py) | AI Layer | PhÃ¢n loáº¡i, trÃ­ch Ä‘áº·c trÆ°ng, DL model |
| gui_app.py | UI | Giao diá»‡n Tkinter, hiá»ƒn thá»‹ Dashboard |
| api.py | API Server | Flask REST API cho remote control |
| sound_service.py | Service | TÃ­ch há»£p high-level, quáº£n lÃ½ vÃ²ng láº·p |

---

## ğŸ¬ TÃ“MEÃ LUá»’NG THá»°C THI

**Entry Point:**
```
smart_audio_pipeline.py (if __name__ == "__main__")
    â†“
SmartAudioSystem() init (Khá»Ÿi táº¡o)
    â†“
.start() (Má»Ÿ stream mic)
    â†“
.run_demo() (VÃ²ng láº·p chÃ­nh)
    â†“
.process_and_predict() â­ TRUNG TÃ‚M
    â”œâ”€ Read Mic (RAW) â†’ AudioClassifier
    â”œâ”€ Process DSP (Clean) â†’ AudioProcessor
    â”œâ”€ Classify Basic (Rule) â†’ AudioClassifier
    â”œâ”€ Extract Features â†’ AudioClassifier
    â””â”€ Predict DL (AI Model) â†’ AudioClassifier + TensorFlow
    â†“
Display Results (Rich Table)
    â†“
Loop â†’ sleep(0.1) â†’ back to process_and_predict()
    â†“
Ctrl+C â†’ .stop() â†’ ÄÃ³ng stream
```

---

## ğŸ”‘ KEY INSIGHT

**smart_audio_pipeline.py** lÃ  file trung tÃ¢m káº¿t há»£p:
1. **DSP Processing** (AudioProcessor) - Xá»­ lÃ½ tÃ­n hiá»‡u
2. **AI Classification** (AudioClassifier) - PhÃ¢n loáº¡i AI + Model DL

VÃ²ng láº·p chÃ­nh á»Ÿ hÃ m `process_and_predict()` liÃªn tá»¥c:
- Äá»c audio tá»« mic
- Lá»c nhiá»…u
- PhÃ¢n loáº¡i rule-based
- Gá»i Deep Learning model
- Hiá»ƒn thá»‹ káº¿t quáº£

**Tá»‘c Ä‘á»™:** ~100ms/chunk (10 chunks/giÃ¢y)
